{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UHiG3Ds44d_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 데이터 다시 로드\n",
        "df = pd.read_csv('train_data.csv')\n",
        "\n",
        "# 데이터 전처리\n",
        "processed_data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    question = row['문제']\n",
        "\n",
        "    # 선택지를 쉼표로 분리하여 리스트로 변환\n",
        "    options = row['선택지'].strip(\"[]\").split(\", \")  # 문자열에서 리스트 처리\n",
        "\n",
        "    correct_answer = row['답안'] - 1  # 답안이 1부터 시작하므로 0부터 시작하게 조정\n",
        "\n",
        "    processed_data.append({\n",
        "        \"question\": question,\n",
        "        \"options\": options,\n",
        "        \"correct_answer\": correct_answer\n",
        "    })\n",
        "\n",
        "# 전처리된 데이터를 DataFrame으로 변환\n",
        "processed_df = pd.DataFrame(processed_data)\n",
        "\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "processed_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "# 데이터를 콘솔에 출력\n",
        "print(processed_df.head())"
      ],
      "metadata": {
        "id": "Mj82Jxzc47An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제가 되는 따옴표를 처리하여 선택지를 올바르게 처리하기\n",
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "file_path = 'train_data.csv'\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 전처리\n",
        "processed_data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    question = row['문제']\n",
        "\n",
        "    # 선택지 문자열의 형식을 확인하고 리스트로 변환\n",
        "    try:\n",
        "        options = ast.literal_eval(row['선택지'])\n",
        "    except:\n",
        "        # 문제가 있는 경우, 그대로 문자열을 유지하고 continue\n",
        "        print(f\"Error parsing options at index {index}: {row['선택지']}\")\n",
        "        continue\n",
        "\n",
        "    # 답안은 이미 0부터 시작하는 인덱스라고 가정\n",
        "    correct_answer = row['답안']\n",
        "\n",
        "    processed_data.append({\n",
        "        \"question\": question,\n",
        "        \"options\": options,\n",
        "        \"correct_answer\": correct_answer\n",
        "    })\n",
        "\n",
        "# 전처리된 데이터를 DataFrame으로 변환\n",
        "processed_df = pd.DataFrame(processed_data)\n",
        "\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "processed_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "# 데이터를 콘솔에 출력\n",
        "print(processed_df.head())"
      ],
      "metadata": {
        "id": "JR6L5xsq49t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrected_options = {\n",
        "    2943: [\n",
        "        \"국가가 안정성을 제공하지 못함으로써 사회의 각 구성 요소가 자신의 안녕을 유지하기 위해 경쟁하게 되어 불안을 초래하는 상황을 말합니다. 이 조건은 자가 증식적이며, 체제를 확보하기 위한 조치가 더 큰 저항을 불러일으키기 때문에 반영구적인 긴급 무정부 상태가 됩니다.\",\n",
        "        \"약소국의 불안정 딜레마는 주로 외부 조건으로 인해 발생하며, 구조적 무정부 상태와 유사한 상황을 초래합니다. 약소국이 자국의 지역적 입지를 개선하기 위한 조치를 취할 때 지역 내 불안을 조성합니다.\",\n",
        "        \"약소국의 불안정 딜레마는 사회의 각 구성 요소가 자신의 안녕과 이익을 보호하고 유지하기 위한 경쟁에서 비롯됩니다. 그러나 지배 엘리트는 사회적 경쟁 영역과 분리되어 정책 딜레마를 초래합니다. 질서를 회복하기 위해 폭력 수단을 사용할 경우 체제의 기반이 약화됩니다.\",\n",
        "        \"약소국의 불안정 딜레마는 정치적 및 제도적 중심화와 힘의 독점이 부족한 상황에서 발생합니다. 그러나 제도를 강화하기 위해 무력을 동원하면 이 과정을 중단시킬 수 있습니다. '국가성'을 육성하지 못하는 것은 폭력 사용으로 반전됩니다. 사회적 불안은 긴급하지만 개발되지 않은 무정부 상태의 반영구적 상황입니다.\"\n",
        "    ],\n",
        "    3257: [\n",
        "        \"모든 RNA가 공통된 3' 말단에서 끝나고 중첩된 세트 전사체를 생성합니다.\",\n",
        "        \"긴 RNA 유전체와의 재조합을 이용합니다.\",\n",
        "        \"변이율이 높지 않습니다.\",\n",
        "        \"캡이 씌워진 세포 mRNA를 사용합니다.\"\n",
        "    ],\n",
        "    4411: [\n",
        "        \"정치적 편견 없이 진실되고 정확한 설명이어야 한다.\",\n",
        "        \"생존하지 못한 유사한 모든 문서를 대표해야 한다.\",\n",
        "        \"문자 그대로의 의미와 해석 가능한 의미를 모두 가져야 한다.\",\n",
        "        \"알려진 저자의 '신뢰할 수 있는' 원본 또는 신뢰할 수 있는 사본이어야 한다.\"\n",
        "    ],\n",
        "    5439: [\n",
        "        \"가난한 사람들이 상대적으로 박탈감을 느끼게 하는 문화적으로 가치 있는 상품과 생활 수준.\",\n",
        "        \"사람이 급여나 임금에서 받는 금전의 흐름.\",\n",
        "        \"토지, 주식 및 은행 예금을 포함한 경제적 자원의 축적.\",\n",
        "        \"다양한 양의 재산을 소유한 인구의 '부분'.\"\n",
        "    ],\n",
        "    7115: [\n",
        "        \"석유 생산국의 체제에 대한 도전이 없는 상태.\",\n",
        "        \"생산, 수출 및 공급의 현상 유지가 유지되는 정치적 및 경제적 상황.\",\n",
        "        \"석유 생산국 내에서 인간 안보와 관련된 환경 안보를 우선시하는 것.\",\n",
        "        \"북미, 유럽 및 국제 석유 회사의 이익에 의해 '우호적'으로 간주되는 체제의 안보.\"\n",
        "    ],\n",
        "    8856: [\n",
        "        \"남반구의 에너지 매장량을 통제하려는 시도는 핵심 강대국 간 협력의 지속 가능성에 영향을 미칩니다. 이러한 통제 형태에 대한 지정학적 경쟁의 출현은 국제 안보에 영향을 미칩니다.\",\n",
        "        \"이 모든 옵션.\",\n",
        "        \"에너지 자원의 생산과 공급에 대한 공통된 불안으로 인해 국제 행위자들은 협상에 강요되고 국가 간 협력이 증가합니다.\",\n",
        "        \"글로벌 '북반구'가 접근을 원하는 에너지 자원을 통해 '남반구' 국가는 국제 무대에서 힘을 얻고, 글로벌 북-남 간 격차와 관련된 불평등을 시정했습니다.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 수정된 선택지 데이터를 원본 데이터에 반영\n",
        "for idx, options in corrected_options.items():\n",
        "    df.at[idx, '선택지'] = str(options)\n",
        "\n",
        "# 다시 전처리 실행\n",
        "processed_data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    question = row['문제']\n",
        "\n",
        "    try:\n",
        "        options = ast.literal_eval(row['선택지'])\n",
        "    except:\n",
        "        print(f\"Error parsing options at index {index}: {row['선택지']}\")\n",
        "        continue\n",
        "\n",
        "    correct_answer = row['답안']\n",
        "\n",
        "    processed_data.append({\n",
        "        \"question\": question,\n",
        "        \"options\": options,\n",
        "        \"correct_answer\": correct_answer\n",
        "    })\n",
        "\n",
        "# 전처리된 데이터를 DataFrame으로 변환\n",
        "processed_df = pd.DataFrame(processed_data)\n",
        "# 데이터프레임을 CSV 파일로 저장\n",
        "processed_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "# 데이터를 콘솔에 출력\n",
        "print(processed_df.info())"
      ],
      "metadata": {
        "id": "1vopgODb4_1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# KoBERT 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
        "\n",
        "# 전처리된 데이터셋을 KoBERT 입력 형식으로 변환\n",
        "class MultipleChoiceDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.dataframe.iloc[idx]['question']\n",
        "        options = self.dataframe.iloc[idx]['options']\n",
        "        correct_answer = int(self.dataframe.iloc[idx]['correct_answer'])\n",
        "\n",
        "        # 질문과 각 선택지를 토큰화 및 인코딩\n",
        "        inputs = self.tokenizer(\n",
        "            [question] * len(options),\n",
        "            options,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'],\n",
        "            'attention_mask': inputs['attention_mask'],\n",
        "            'labels': torch.tensor(correct_answer, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# DataLoader에서 패딩을 처리하기 위한 collate_fn 정의\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n",
        "\n",
        "    # 선택지 수가 다른 문제를 해결하기 위해 패딩\n",
        "    max_choices = max([x.size(0) for x in input_ids])\n",
        "\n",
        "    padded_input_ids = []\n",
        "    padded_attention_mask = []\n",
        "\n",
        "    for i in range(len(input_ids)):\n",
        "        padding = (0, 0, 0, max_choices - input_ids[i].size(0))\n",
        "        padded_input_ids.append(torch.nn.functional.pad(input_ids[i], padding, value=tokenizer.pad_token_id))\n",
        "        padded_attention_mask.append(torch.nn.functional.pad(attention_mask[i], padding, value=0))\n",
        "\n",
        "    return {\n",
        "        'input_ids': torch.stack(padded_input_ids),\n",
        "        'attention_mask': torch.stack(padded_attention_mask),\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "# Dataset 생성\n",
        "dataset = MultipleChoiceDataset(processed_df, tokenizer)\n",
        "\n",
        "# DataLoader 생성 (collate_fn 포함)\n",
        "loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 첫 번째 배치 확인\n",
        "for batch in loader:\n",
        "    print(batch)\n",
        "    break"
      ],
      "metadata": {
        "id": "p90G8tqV5E_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# DataLoader에서 인코딩된 데이터를 추출\n",
        "encoded_data = []\n",
        "\n",
        "for batch in loader:\n",
        "    batch_data = {\n",
        "        'input_ids': batch['input_ids'].tolist(),\n",
        "        'attention_mask': batch['attention_mask'].tolist(),\n",
        "        'labels': batch['labels'].tolist()\n",
        "    }\n",
        "    encoded_data.append(batch_data)\n",
        "\n",
        "# 파일로 저장\n",
        "with open('encoded_kobert_data.pkl', 'wb') as f:\n",
        "    pickle.dump(encoded_data, f)"
      ],
      "metadata": {
        "id": "WZJQiIaB5HY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickle 파일 열기\n",
        "with open('encoded_kobert_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# 데이터 확인\n",
        "print(data)"
      ],
      "metadata": {
        "id": "JgIvJj3C5K65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구조 확인\n",
        "print(type(data))  # 데이터 타입 출력 (예: list, dict)\n",
        "print(data[0])  # 첫 번째 데이터 샘플 출력"
      ],
      "metadata": {
        "id": "Mu-IPCWl5Lnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "# Pickle 파일 로드\n",
        "with open('encoded_kobert_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open('encoded_kobert_data.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(data, json_file, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "U556gRWh5Nep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}